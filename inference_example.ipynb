{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c50c72a3",
   "metadata": {},
   "source": [
    "# Inference and Scoring\n",
    "\n",
    "* 표준어 > 경상도 예시입니다.\n",
    "* 예시로 사용한 모델은 1 epoch만 학습한 모델입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6caa0b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BartForConditionalGeneration\n",
    "from kobart import get_pytorch_kobart_model, get_kobart_tokenizer\n",
    "from tqdm import tqdm\n",
    "from torchtext.data.metrics import bleu_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa07773",
   "metadata": {},
   "source": [
    "## load tokenizer & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0829a102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/eunjin/dialect_convert/projects/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_kobart_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed123a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BartForConditionalGeneration.from_pretrained('model_results/s2d/kyeongsang/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2656fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> model set\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.to('cuda')\n",
    "print('>> model set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3317049",
   "metadata": {},
   "source": [
    "## load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f45fa408",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('data/kyeongsang/test_cleaned.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33d9a84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>standard</th>\n",
       "      <th>dialect</th>\n",
       "      <th>mp_d</th>\n",
       "      <th>mp_s</th>\n",
       "      <th>mp_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4820</th>\n",
       "      <td>잘 시켜서 먹더라 어제도 스치로폼 한 박스가 와서 뜯어 보니깐</td>\n",
       "      <td>잘 시키가 묵드라 어제도 스치로폼 한 박스가 와서 뜯어 보니깐</td>\n",
       "      <td>시키가_묵드라</td>\n",
       "      <td>시켜서_먹더라</td>\n",
       "      <td>2 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10928</th>\n",
       "      <td>애들은 편하게 있고 그런 식으로 해가지고 오히려 조금</td>\n",
       "      <td>애들은 편하게 있고 그런 식으로 해가지고 오히려 쫌</td>\n",
       "      <td>쫌</td>\n",
       "      <td>조금</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11301</th>\n",
       "      <td>내가 대신 교수님한테 제출하고 이렇게 했단 말이에요 그래서</td>\n",
       "      <td>내가 대신 교수님한테 제출하고 이켔단 말이에요 그래서</td>\n",
       "      <td>이켔단</td>\n",
       "      <td>이렇게 했단</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 standard                             dialect  \\\n",
       "4820   잘 시켜서 먹더라 어제도 스치로폼 한 박스가 와서 뜯어 보니깐  잘 시키가 묵드라 어제도 스치로폼 한 박스가 와서 뜯어 보니깐   \n",
       "10928       애들은 편하게 있고 그런 식으로 해가지고 오히려 조금        애들은 편하게 있고 그런 식으로 해가지고 오히려 쫌   \n",
       "11301    내가 대신 교수님한테 제출하고 이렇게 했단 말이에요 그래서       내가 대신 교수님한테 제출하고 이켔단 말이에요 그래서   \n",
       "\n",
       "          mp_d     mp_s mp_idx  \n",
       "4820   시키가_묵드라  시켜서_먹더라    2 3  \n",
       "10928        쫌       조금      8  \n",
       "11301      이켔단   이렇게 했단      5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18312ebc",
   "metadata": {},
   "source": [
    "### inference test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91703f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  토익을 한 번 쳤었는데 한 번 아니고 두 번 쳤었지.\n",
      "gold:  토익을 한 번 쳤었는데 한 번 아이고 두 번 쳤었지.\n",
      "generation:  <usr> 토익을 한 번 쳤었는디 한 번 아니고 두 번 쳤었지.</s>\n"
     ]
    }
   ],
   "source": [
    "idx = 6013\n",
    "sent = test_df['standard'][idx]\n",
    "print('input: ' , sent)\n",
    "print('gold: ' , test_df['dialect'][idx])\n",
    "# prepare input\n",
    "inputs=tokenizer(sent,return_tensors='pt')\n",
    "# max_length, num_beams are hypperparameters\n",
    "outputs=model.generate(inputs['input_ids'].to('cuda'), eos_token_id=1, max_length=128, num_beams=5)\n",
    "print('generation: ', tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee04b8e9",
   "metadata": {},
   "source": [
    "### scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae0cb3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:22<00:00,  4.49it/s]\n"
     ]
    }
   ],
   "source": [
    "preds=[]\n",
    "for sent in tqdm(test_df['standard'][:100]):\n",
    "    inputs=tokenizer(sent,return_tensors='pt')\n",
    "    outputs=model.generate(inputs['input_ids'].to('cuda'), eos_token_id=1, max_length=128, num_beams=5)\n",
    "    preds.append(tokenizer.decode(outputs[0][1:-1])) # remove special tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d00ed9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [p.split() for p in preds]\n",
    "targets = [[d.split()] for d in test_df['dialect'][:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc9855d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8944592475891113"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_score(preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8fde09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
